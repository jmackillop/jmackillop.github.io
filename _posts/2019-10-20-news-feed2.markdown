---
layout: post
title:  "News Feed by Event: TFIDF Vectorization and DBSCAN Clustering"
date:   2019-10-20 15:01:26 +0100
categories: news-feed news data clustering scraping tfidf dbscan
---


<p><i>This is the second in a series of posts that will explain how I built a news feed that groups articles based on news event.</i></p>

<h2 class="heading"> TF-IDF Vectorization </h2>

<p>Once named entity recognition is performed, the next step is to perform tf-idf vectorization of the named entities. This involves, for each article, counting the frequency of the named entities (Term Frequency), and then weighting them by how common they are in a large corpus (Inverse Document Frequency). Using tf-idf, terms that occur very frequently in the corpus, such as 'the' or 'and', will receive much lower weights than unusual terms, such as 'tyrannosaurus rex', for a given frequency in the target text. This effectively acts to measure the level of surprise or importance of terms - seeing 'government' five times in an article gives us much less information about the news event than seeing 'tyrannosaurus rex' five times. </p>

<p>To begin tf-idf vectorization, first the corpus must be collected. The corpus is 10,000 recent articles from the Reuters news archives, collected using a similar method as for the headline articles - see reuters-corpus.py for the implementation. I then use CountVectorizer followed by TfidfTransformer to get the idf values for the named entities, our 'vocabulary', from the corpus. The tf-idf values then are found by multiplying the frequency of the named entities in the headline articles by the corresponding idf values. This gives, for each article, a vector of tf-idf values of length equal to the number of named entities among all the headline articles. These vectors can be thought of as a 'description' of each article in terms of the weighted importance of named entities in the article.</p>

{% highlight python %}

# Reuters
rr = requests.get('https://uk.reuters.com/news/world')
all_reuters_link_endings = re.findall(r'<a href="(/article/.+?)"', rr.text)

{% endhighlight %}


<p>In <a href='https://jmackillop.ml/projects/lob-part2'>the second part</a>, I look at tf-idf vectorization of the named entities and clustering the articles into events based on this.</p>